# Text Generation
## Introduction

## Papers
### Deep Reinforcement Learning Based
1. **Using Semantic Similarity as Reward for Reinforcement Learning in Sentence Generation**. *ACL 2019*. [[PDF](https://pdfs.semanticscholar.org/6a53/a38e1b160ab70f4a0f84ceff906ac84d9b12.pdf)]

### Neural Network Based
1. Towards Generating Long and Coherent Text with Multi-Level Latent Variable Models. *ACL 2019*. [[PDF](https://arxiv.org/pdf/1902.00154)]
2. Sentence-Level Content Planning and Style Specification for Neural Text Generation. *EMNLP 2019*. [[PDF](https://arxiv.org/pdf/1909.00734)]
3. Denoising-based Sequence-to-Sequence Pre-training for Text Generation. *EMNLP 2019*. [[PDF](https://arxiv.org/pdf/1908.08206)]
4. A Graph-to-Sequence Model for AMR-to-Text Generation. *ACL 2018*. [[PDF](https://arxiv.org/pdf/1805.02473)]
5. Controlling Global Statistics in Recurrent Neural Network Text Generation. *AAAI 2018*. [[PDF](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16961/16085)]
6. Long Text Generation via Adversarial Training with Leaked Information. *AAAI 2018*. [[PDF](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPDFInterstitial/16360/16061)]
7. Order-Planning Neural Text Generation From Structured Data. *AAAI 2018*. [[PDF](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/download/16203/16095)]
8. Table-to-text Generation by Structure-aware Seq2seq Learning. *AAAI 2018*. [[PDF](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPDFInterstitial/16599/16019)]
9. Diverse and Coherent Paragraph Generation from Images. *ECCV 2018*. [[PDF]( https://eccv2018.org/openaccess/content_ECCV_2018/papers/Moitreya_Chatterjee_Diverse_and_Coherent_ECCV_2018_paper.pdf )]
10. Differentiated Distribution Recovery for Neural Text Generation. *AAAI 2019*. [[PDF]()]
11. **Enhancing Variational Autoencoders with Mutual Information Neural Estimation for Text Generation**. *ACL 2019*. [[PDF](https://www.aclweb.org/anthology/D19-1416.pdf)]
12. Data-to-Text Generation with Content Selection and Planning. *AAAI 2019*. [[PDF](https://wvvw.aaai.org/ojs/index.php/AAAI/article/download/4668/4546)]
13. Hierarchical Encoder with Auxiliary Supervision for Table-to-text Generation: Learning Better Representation for Tables. *AAAI 2019*. [[PDF]()]
14. ParaBank: Monolingual Bitext Generation and Sentential Paraphrasing via Lexicallyconstrained Neural Machine Translation. *AAAI 2019*. [[PDF]()]
15. A Topic Augmented Text Generation Model: Joint Learning of Semantics and Structural Features. *EMNLP 2019*. [[PDF]()]
16. ARAML: A Stable Adversarial Training Framework for Text Generation. *EMNLP 2019*. [[PDF]()]
17. Deep Copycat Networks for Text-to-Text Generation. *EMNLP 2019*. [[PDF]()]
18. Enhancing AMR-to-Text Generation with Dual Graph Representations. *EMNLP 2019*. [[PDF]()]
19. Enhancing Neural Data-To-Text Generation Models with External Background Knowledge. *EMNLP 2019*. [[PDF]()]
20. Implicit Deep Latent Variable Models for Text Generation. *EMNLP 2019*. [[PDF]()]
21. Long and Diverse Text Generation with Planning-based Hierarchical Variational Model. *EMNLP 2019*. [[PDF]()]
22. Modeling Graph Structure in Transformer for Better AMR-to-Text Generation. *EMNLP 2019*. [[PDF]()]
23. MoverScore: Text Generation Evaluating with Contextualized Embeddings and Earth Mover Distance. *EMNLP 2019*. [[PDF]()]
24. Neural data-to-text generation: A comparison between pipeline and end-to-end architectures. *EMNLP 2019*. [[PDF]()]
25. Select and Attend: Towards Controllable Content Selection in Text Generation. *EMNLP 2019*. [[PDF]()]
26. Table-to-Text Generation with Effective Hierarchical Encoder on Three dimensions (Row, Column and Time). *EMNLP 2019*. [[PDF]()]
27. Autoregressive Text Generation beyond Feedback Loops. *EMNLP 2019*. [[PDF](https://arxiv.org/pdf/1908.11658)]



### Metrics for Text Generation
1. A Cross-Domain Transferable Neural Coherence Model. *ACL 2019*. [[PDF](https://arxiv.org/pdf/1905.11912)]
2. Sentence Mover's Similarity Automatic Evaluation for Multi-Sentence Texts. *ACL 2019*. [[PDF](https://pdfs.semanticscholar.org/7164/b4cb89b268dd4887fc029488393c4c249306.pdf)]

### NAACL2018
## Long Papers
**Discourse-Aware Neural Rewards for Coherent Text Generation**
*In this paper, we investigate the use of discourse-aware rewards with reinforcement learning to guide a model to generate long, coherent text.*

**Neural Text Generation in Stories Using Entity Representations as Context**
*We introduce an approach to neural text generation that explicitly represents entities mentioned in the text.*

**A Deep Ensemble Model with Slot Alignment for Sequence-to-Sequence Natural Language Generation**
*We describe an ensemble neural language generator, and present several novel methods for data representation and augmentation that yield improved results in our model.*

**Natural Answer Generation with Heterogeneous Memory**
*In this work, we propose a novel attention mechanism to encourage the decoder to actively interact with the memory by taking its heterogeneity into account.*

**Query and Output: Generating Words by Querying Distributed Word Representations for Paraphrase Generation**
*We present a neural model for question generation from knowledge graphs triples in a “Zero-shot” setup, that is generating questions for predicate, subject types or object types that were not seen at training time.*

**Zero-Shot Question Generation from Knowledge Graphs for Unseen Predicates and Entity Types**
*We present a neural model for question generation from knowledge graphs triples in a “Zero-shot” setup, that is generating questions for predicate, subject types or object types that were not seen at training time.*

**What’s This Movie About? A Joint Neural Network Architecture for Movie Content Analysis**
*We present a novel end-to-end model for overview generation, consisting of a multi-label encoder for identifying screenplay attributes, and an LSTM decoder to generate natural language sentences conditioned on the identified attributes. We create a dataset that consists of movie scripts, attribute-value pairs for the movies’ aspects, as well as overviews, which we extract from an online database.*

**Interpretable Charge Predictions for Criminal Cases: Learning to Generate Court Views from Fact Descriptions**
*In this paper, we propose to study the problem of court view generation from the fact description in a criminal case.*

**Adversarial Example Generation with Syntactically Controlled Paraphrase Networks**
*We propose syntactically controlled paraphrase networks (SCPNs) and use them to generate adversarial examples.*

**Dialog Generation Using Multi-Turn Reasoning Neural Networks**
*In this paper, we propose a generalizable dialog generation approach that adapts multi-turn reasoning, one recent advancement in the field of document comprehension, to generate responses (“answers”) by taking current conversation session context as a “document” and current query as a “question”.*

**Neural Text Generation in Stories Using Entity Representations as Context**
*We introduce an approach to neural text generation that explicitly represents entities mentioned in the text.*

## Short Papers

**Automatic Dialogue Generation with Expressed Emotions**
*In this research, we address the problem of forcing the dialogue generation to express emotion.*

**Guiding Generation for Abstractive Text Summarization Based on Key Information Guide Network**
*We propose a guiding generation model that combines the extractive method and the abstractive method.*

**Natural Language Generation by Hierarchical Decoding with Linguistic Patterns**
*This paper introduces a hierarchical decoding NLG model based on linguistic patterns in different levels, and shows that the proposed method outperforms the traditional one with a smaller model size.*

**RankME: Reliable Human Ratings for Natural Language Generation**
*We present a novel rank-based magnitude estimation method (RankME), which combines the use of continuous scales and relative assessments.*

**Identifying the Most Dominant Event in a News Article by Mining Event Coreference Relations**
*Identifying the most dominant and central event of a document, which governs and connects other foreground and background events in the document, is useful for many applications, such as text summarization, storyline generation and text segmentation.*
  
**Leveraging Context Information for Natural Question Generation**
*We propose a model that matches the answer with the passage before generating the question.*

**TypeSQL: Knowledge-Based Type-Aware Neural Text-to-SQL Generation**
*In this paper, we present a novel approach TypeSQL which formats the problem as a slot filling task in a more reasonable way.*

**Learning to Generate Wikipedia Summaries for Underserved Languages from Wikidata**
*In this work, we investigate the generation of open domain Wikipedia summaries in underserved languages using structured data from Wikidata.*

**Natural Language to Structured Query Generation via Meta-Learning**
*In this work, we explore a different learning protocol that treats each example as a unique pseudo-task, by reducing the original learning problem to a few-shot meta-learning scenario with the help of a domain-dependent relevance function.*


